# ğŸ® Pokemon Red RL Agent

Ein Reinforcement Learning Agent, der lernt, Pokemon Rot zu spielen und zum Pokemon-Liga Champion zu werden.

## ğŸ“‹ Inhaltsverzeichnis

- [Ãœber das Projekt](#Ã¼ber-das-projekt)
- [Features](#features)
- [Installation](#installation)
- [Verwendung](#verwendung)
- [Projektstruktur](#projektstruktur)
- [Wie funktioniert es?](#wie-funktioniert-es)
- [Training Konfiguration](#training-konfiguration)
- [Troubleshooting](#troubleshooting)
- [Roadmap](#roadmap)

## ğŸ¯ Ãœber das Projekt

Dieses Projekt nutzt **Reinforcement Learning** (speziell den PPO-Algorithmus), um eine KI zu trainieren, die Pokemon Rot selbststÃ¤ndig spielt. Die KI lernt durch Trial-and-Error, indem sie Belohnungen fÃ¼r Fortschritte erhÃ¤lt (neue Gebiete erkunden, Pokemon fangen, Badges gewinnen).

### Technologie-Stack

- **Python 3.13**
- **PyBoy** - Game Boy Emulator
- **Stable-Baselines3** - Reinforcement Learning Framework (PPO)
- **Gymnasium** - RL Environment Standard
- **OpenCV** - Bildverarbeitung
- **PyTorch** - Deep Learning Backend

## âœ¨ Features

âœ… **Automatisches Intro-Ãœberspringen** - Startet direkt im Spiel  
âœ… **Intelligentes Reward-System** - Belohnungen fÃ¼r Exploration, Pokemon fangen, Badges  
âœ… **Checkpoint-System** - Speichert automatisch alle 50.000 Steps  
âœ… **Resume-Funktion** - Training fortsetzbar nach Unterbrechung  
âœ… **RAM-basierte Belohnungen** - PrÃ¤zise Fortschrittserkennung Ã¼ber Game Boy RAM  
âœ… **Headless Training** - Training ohne GUI fÃ¼r maximale Performance  
âœ… **Watch Mode** - KI beim Spielen live zuschauen  

## ğŸ“¦ Installation

### Voraussetzungen

- **Linux** (getestet auf Arch Linux)
- **Python 3.13+**
- **CUDA** (optional, fÃ¼r GPU-Training)
- Pokemon Red ROM-Datei (legal nur mit Original-Spielmodul)

### Schritt 1: Repository klonen

```bash
git clone https://github.com/Uruskus/Pokemon_RL.git
cd Pokemon_RL
```

### Schritt 2: Virtuelle Umgebung erstellen

```bash
python -m venv venv
source venv/bin/activate.fish  # fÃ¼r fish shell
# oder
source venv/bin/activate       # fÃ¼r bash/zsh
```

### Schritt 3: Dependencies installieren

```bash
pip install --upgrade pip
pip install gymnasium pyboy opencv-python numpy stable-baselines3 torch tensorboard
```

**Optional fÃ¼r GPU-Support (NVIDIA):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### Schritt 4: ROM-Datei hinzufÃ¼gen

Platziere deine Pokemon Red ROM-Datei im Projektordner:
```
Pokemon_RL/
â”œâ”€â”€ pokemon_red.gb  â† Hier!
â”œâ”€â”€ pokemon_rl_env.py
â”œâ”€â”€ train.py
â””â”€â”€ watch.py
```

**Wichtig:** Du musst eine Original-Pokemon-Rot-Kassette besitzen, um die ROM legal zu verwenden.

## ğŸš€ Verwendung

### Training starten

```bash
python train.py
```

**Das Training:**
- LÃ¤uft fÃ¼r **10 Millionen Steps** (dauert mehrere Stunden/Tage)
- Speichert automatisch alle 50.000 Steps
- Kann jederzeit mit `CTRL+C` pausiert werden
- Fortsetzung beim Neustart automatisch

**Ausgabe:**
```
==================================================
ITERATION 1/10
Progress: 0.0% | Steps: 0/10,000,000
==================================================

fps: 300 | ep_rew_mean: 1810 | total_timesteps: 136,793
```

### Training pausieren

```bash
# Im laufenden Training:
CTRL+C
```

Das Model wird automatisch als `models/pokemon_model_backup.zip` gespeichert.

### Training fortsetzen

```bash
python train.py
```

Das Script lÃ¤dt automatisch das letzte Model (`models/pokemon_model_latest.zip`).

### KI beim Spielen zuschauen

```bash
python watch.py
```

**Was passiert:**
- LÃ¤dt das trainierte Model
- Ã–ffnet ein Fenster mit dem Spiel
- Die KI spielt live vor deinen Augen
- Console zeigt Actions und Rewards

**Abbrechen:** `CTRL+C`

## ğŸ“ Projektstruktur

```
Pokemon_RL/
â”œâ”€â”€ pokemon_rl_env.py      # Gymnasium Environment (Spiel-Interface)
â”œâ”€â”€ train.py               # Training Script
â”œâ”€â”€ watch.py               # Visualisierung Script
â”œâ”€â”€ pokemon_red.gb         # Pokemon Red ROM (nicht im Git!)
â”œâ”€â”€ .gitignore            # Ignorierte Dateien
â”œâ”€â”€ README.md             # Diese Datei
â”‚
â”œâ”€â”€ models/               # Trainierte Models (automatisch erstellt)
â”‚   â”œâ”€â”€ pokemon_model_latest.zip
â”‚   â”œâ”€â”€ pokemon_model_1m_steps.zip
â”‚   â”œâ”€â”€ pokemon_model_2m_steps.zip
â”‚   â””â”€â”€ pokemon_checkpoint_*.zip
â”‚
â””â”€â”€ logs/                 # Tensorboard Logs (automatisch erstellt)
    â””â”€â”€ PPO_0/
```

## ğŸ§  Wie funktioniert es?

### 1. Environment (`pokemon_rl_env.py`)

Die KI interagiert mit dem Spiel Ã¼ber ein **Gymnasium Environment**:

**Observations (Was sieht die KI?):**
- Grayscale Screenshot (144x160 Pixel)
- Optional: RAM-Werte (Position, Pokemon, Badges)

**Actions (Was kann die KI tun?):**
- 0: No-Op (nichts)
- 1: A
- 2: B
- 3: Start
- 4: Select
- 5: Up
- 6: Down
- 7: Left
- 8: Right

**Rewards (WofÃ¼r bekommt die KI Punkte?):**
- +0.1 fÃ¼r Bewegung (Exploration)
- +5.0 fÃ¼r neue Map
- +20.0 fÃ¼r neues Pokemon gefangen
- +100.0 fÃ¼r neuen Badge
- -0.1 fÃ¼r Stillstand (Penalty)

### 2. Training Algorithm (PPO)

**Proximal Policy Optimization (PPO):**
- Moderner RL-Algorithmus
- Stabil und effizient
- Lernt aus vergangenen Episoden
- Verwendet CNN (Convolutional Neural Network) fÃ¼r Bildverarbeitung

### 3. Training Loop

```
1. Start Episode
2. Ãœberspringe Intro automatisch
3. FÃ¼r 10.000 Steps:
   - KI wÃ¤hlt Action
   - Spiel fÃ¼hrt Action aus
   - KI bekommt Reward
   - KI lernt aus Erfahrung
4. Episode beendet â†’ Reset
5. Wiederhole mit besserer Policy
```

Nach Millionen von Steps lernt die KI:
- MenÃ¼s zu navigieren
- Zielgerichtet zu laufen
- Mit NPCs zu interagieren
- Pokemon zu fangen und zu trainieren
- Arenen zu besiegen

## âš™ï¸ Training Konfiguration

### Training-Parameter anpassen

In `train.py` kannst du folgendes Ã¤ndern:

```python
# Gesamt-Steps
total_steps = 10_000_000  # Standard: 10 Millionen

# Checkpoint-Frequenz
save_freq=50000  # Speichert alle 50k Steps

# PPO Hyperparameter
model = PPO(
    "CnnPolicy",
    env,
    n_steps=2048,        # Steps pro Update
    batch_size=64,       # Batch Size
    learning_rate=0.0003,  # Learning Rate
    n_epochs=10,         # Epochs pro Update
)
```

### Episode-LÃ¤nge Ã¤ndern

In `pokemon_rl_env.py` Zeile ~258:

```python
# Aktuelle Einstellung: 10.000 Steps pro Episode
done = self.stats['current_episode_steps'] >= 10000

# FÃ¼r lÃ¤ngere Episodes:
done = self.stats['current_episode_steps'] >= 50000
```

### Reward-System anpassen

In `pokemon_rl_env.py` in der `_calculate_reward()` Funktion:

```python
# Beispiel: HÃ¶here Belohnung fÃ¼r neue Maps
if map_id != self.prev_state['map_id']:
    reward += 10.0  # Statt 5.0
```

## ğŸ”§ Troubleshooting

### Problem: "ImportError: libtk8.6.so"

**LÃ¶sung:**
```bash
sudo pacman -S tk python-tk
```

### Problem: "ROM nicht gefunden"

**LÃ¶sung:**
```bash
# PrÃ¼fe ob ROM im richtigen Ordner ist
ls -la pokemon_red.gb

# Stelle sicher der Name exakt "pokemon_red.gb" ist
```

### Problem: Training zu langsam

**LÃ¶sungen:**
- Nutze GPU (CUDA):
  ```bash
  pip install torch --index-url https://download.pytorch.org/whl/cu118
  ```
- Reduziere `n_steps` in `train.py` von 2048 auf 1024
- SchlieÃŸe andere Programme

### Problem: KI macht keinen Fortschritt

**MÃ¶gliche GrÃ¼nde:**
- **Zu wenig Training** - Mindestens 1-5 Millionen Steps nÃ¶tig
- **Reward-System unbalanciert** - Mehr Belohnungen fÃ¼r Zwischenziele
- **Episode zu kurz** - ErhÃ¶he auf 50.000 Steps

**Verbesserungen:**
```python
# In pokemon_rl_env.py - StÃ¤rkere Rewards
if party_count > self.prev_state['party_count']:
    reward += 50.0  # Statt 20.0
```

### Problem: "CUDA out of memory"

**LÃ¶sung:**
```bash
# Reduziere Batch Size in train.py
batch_size=32  # Statt 64
```

## ğŸ—ºï¸ Roadmap

### âœ… Abgeschlossen
- [x] Basic Environment Setup
- [x] Intro-Skip Automatisierung
- [x] Reward-System Implementation
- [x] Checkpoint-System
- [x] Training & Watch Scripts

### ğŸš§ In Arbeit
- [ ] 10 Millionen Steps Training
- [ ] Hyperparameter Tuning
- [ ] Reward-System Optimierung

### ğŸ“ Geplant
- [ ] Savestate-System (statt immer vom Anfang)
- [ ] Curriculum Learning (schrittweise schwieriger)
- [ ] Multi-Environment Training (mehrere Instanzen parallel)
- [ ] Web-Dashboard fÃ¼r Live-Monitoring
- [ ] Pre-trained Model zum Download
- [ ] Twitch-Integration (Live-Stream der KI)

## ğŸ“Š Erwartete Ergebnisse

**Nach verschiedenen Training-Stufen:**

| Steps | Erwartetes Verhalten |
|-------|---------------------|
| 100k | ZufÃ¤lliges Herumlaufen, manchmal MenÃ¼s Ã¶ffnen |
| 1M | VerlÃ¤sst das erste Haus, erkundet Alabastia |
| 5M | Erreicht erste Stadt, fÃ¤ngt Pokemon |
| 10M | Kann erste Arena herausfordern |
| 50M+ | Mehrere Badges, strategisches KÃ¤mpfen |

## ğŸ“ Lizenz

Dieses Projekt ist fÃ¼r Bildungszwecke. Pokemon ist ein Trademark von Nintendo/Game Freak.

**ROM-Hinweis:** Du musst eine originale Pokemon Red Kassette besitzen, um die ROM legal zu verwenden.

## ğŸ¤ Contributing

Contributions sind willkommen! Bitte:
1. Fork das Repository
2. Erstelle einen Feature Branch
3. Commit deine Changes
4. Push zum Branch
5. Ã–ffne einen Pull Request

## ğŸ“§ Kontakt

Bei Fragen oder Problemen Ã¶ffne ein Issue auf GitHub!

---

**Viel Erfolg beim Training deiner Pokemon-KI!** ğŸ®ğŸ¤–
